{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, Dense, Concatenate, Layer\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(data_location = '/kaggle/input/as3-dataset/lexicons'):\n",
    "    def load_tsv(file_path):\n",
    "        data = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                data.append(line.strip().split('\\t'))\n",
    "        return numpy.array(data, dtype=object)\n",
    "\n",
    "    data = {}\n",
    "    for split in ['train', 'dev', 'test']:\n",
    "        file_name = f\"gu.translit.sampled.{split}.tsv\"\n",
    "        file_path = os.path.join(data_location, file_name)\n",
    "        data[split] = load_tsv(file_path)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def tokanize_texts(texts, char_level=True, start_end_tokens=False):\n",
    "    tokenizer = keras.preprocessing.text.Tokenizer(char_level=char_level, filters='', lower=False)\n",
    "\n",
    "    if start_end_tokens:\n",
    "        start_token = '<start>'\n",
    "        end_token = '<end>'\n",
    "        texts = [start_token + text + end_token for text in texts]\n",
    "        \n",
    "    tokenizer.fit_on_texts(texts)\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class seq2seq:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_vocab_size,\n",
    "        output_vocab_size,\n",
    "        embedding_dim,\n",
    "        hidden_units,\n",
    "        encoder_layers,\n",
    "        decoder_layers,\n",
    "        dropout_rate,\n",
    "        recurrent_dropout_rate,\n",
    "        encoder_type,\n",
    "        decoder_type,\n",
    "        beam_width\n",
    "    ):\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_units = hidden_units\n",
    "        self.encoder_layers = encoder_layers\n",
    "        self.decoder_layers = decoder_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.recurrent_dropout_rate = recurrent_dropout_rate\n",
    "        self.beam_width = beam_width\n",
    "        self.encoder_type = encoder_type\n",
    "        self.decoder_type = decoder_type\n",
    "    \n",
    "    def build_training_model(self):\n",
    "        encoder_inputs = keras.layers.Input(shape=(None,), name='encoder_inputs')\n",
    "        encoder_embedding = keras.layers.Embedding(\n",
    "            input_dim=self.input_vocab_size,\n",
    "            output_dim=self.embedding_dim,\n",
    "            mask_zero=True,\n",
    "            name='encoder_embedding'\n",
    "        )(encoder_inputs)\n",
    "\n",
    "        encoder_states = []\n",
    "        encoder_outputs = encoder_embedding\n",
    "\n",
    "        for i in range(self.encoder_layers):\n",
    "            return_sequences = (i < self.encoder_layers - 1)\n",
    "            return_state = True\n",
    "\n",
    "            if self.encoder_type == 'LSTM':\n",
    "                rnn_layer = keras.layers.LSTM(\n",
    "                    units=self.hidden_units,\n",
    "                    return_sequences=return_sequences,\n",
    "                    return_state=return_state,\n",
    "                    dropout=self.dropout_rate,\n",
    "                    recurrent_dropout=self.recurrent_dropout_rate,\n",
    "                    name=f'encoder_{i}'\n",
    "                )\n",
    "\n",
    "                encoder_outputs, state_h, state_c = rnn_layer(encoder_outputs)\n",
    "                encoder_states.extend([state_h, state_c])\n",
    "            \n",
    "            elif self.encoder_type == 'GRU':\n",
    "                rnn_layer = keras.layers.GRU(\n",
    "                    units=self.hidden_units,\n",
    "                    return_sequences=return_sequences,\n",
    "                    return_state=return_state,\n",
    "                    dropout=self.dropout_rate,\n",
    "                    recurrent_dropout=self.recurrent_dropout_rate,\n",
    "                    name=f'encoder_{i}'\n",
    "                )\n",
    "\n",
    "                encoder_outputs, state_h = rnn_layer(encoder_outputs)\n",
    "                encoder_states.append(state_h)\n",
    "\n",
    "            elif self.encoder_type == 'RNN':\n",
    "                rnn_layer = keras.layers.SimpleRNN(\n",
    "                    units=self.hidden_units,\n",
    "                    return_sequences=return_sequences,\n",
    "                    return_state=return_state,\n",
    "                    dropout=self.dropout_rate,\n",
    "                    recurrent_dropout=self.recurrent_dropout_rate,\n",
    "                    name=f'encoder_{i}'\n",
    "                )\n",
    "\n",
    "                encoder_outputs, state_h = rnn_layer(encoder_outputs)\n",
    "                encoder_states.append(state_h)\n",
    "        \n",
    "        decoder_inputs = keras.layers.Input(shape=(None,), name='decoder_inputs')\n",
    "        decoder_embedding = keras.layers.Embedding(\n",
    "            input_dim=self.output_vocab_size,\n",
    "            output_dim=self.embedding_dim,\n",
    "            mask_zero=True,\n",
    "            name='decoder_embedding'\n",
    "        )(decoder_inputs)\n",
    "\n",
    "        decoder_outputs = decoder_embedding\n",
    "        decoder_init_states = []\n",
    "\n",
    "        idx = 0\n",
    "        for i in range(self.decoder_layers):\n",
    "            if i<self.encoder_layers:\n",
    "                if self.decoder_type == 'LSTM':\n",
    "                    h = encoder_states[idx]\n",
    "                    c = encoder_states[idx + 1]\n",
    "                    decoder_init_states.append([h,c])\n",
    "                    idx += 2\n",
    "                else:\n",
    "                    h = encoder_states[idx]\n",
    "                    decoder_init_states.append([h])\n",
    "                    idx += 1\n",
    "            else:\n",
    "                if self.decoder_type == 'LSTM':\n",
    "                    h = encoder_states[-2]\n",
    "                    c = encoder_states[-1]\n",
    "                    decoder_init_states.append([h,c])\n",
    "                else:\n",
    "                    h = encoder_states[-1]\n",
    "                    decoder_init_states.append([h])\n",
    "\n",
    "        for i in range(self.decoder_layers):\n",
    "            return_sequences = True\n",
    "            return_state = True\n",
    "\n",
    "            if self.decoder_type == 'LSTM':\n",
    "                rnn_layer = keras.layers.LSTM(\n",
    "                    units=self.hidden_units,\n",
    "                    return_sequences=return_sequences,\n",
    "                    return_state=return_state,\n",
    "                    dropout=self.dropout_rate,\n",
    "                    recurrent_dropout=self.recurrent_dropout_rate,\n",
    "                    name=f'decoder_{i}'\n",
    "                )\n",
    "                decoder_outputs, _, _ = rnn_layer(decoder_outputs, initial_state=decoder_init_states[i])\n",
    "                \n",
    "            elif self.decoder_type == 'GRU':\n",
    "                rnn_layer = keras.layers.GRU(\n",
    "                    units=self.hidden_units,\n",
    "                    return_sequences=return_sequences,\n",
    "                    return_state=return_state,\n",
    "                    dropout=self.dropout_rate,\n",
    "                    recurrent_dropout=self.recurrent_dropout_rate,\n",
    "                    name=f'decoder_{i}'\n",
    "                )\n",
    "                decoder_outputs, _ = rnn_layer(decoder_outputs, initial_state=decoder_init_states[i])\n",
    "\n",
    "            elif self.decoder_type == 'RNN':\n",
    "                rnn_layer = keras.layers.SimpleRNN(\n",
    "                    units=self.hidden_units,\n",
    "                    return_sequences=return_sequences,\n",
    "                    return_state=return_state,\n",
    "                    dropout=self.dropout_rate,\n",
    "                    recurrent_dropout=self.recurrent_dropout_rate,\n",
    "                    name=f'decoder_{i}'\n",
    "                )\n",
    "                decoder_outputs, _ = rnn_layer(decoder_outputs, initial_state=decoder_init_states[i])\n",
    "\n",
    "        decoder_dense = keras.layers.Dense(\n",
    "            units=self.output_vocab_size,\n",
    "            activation='softmax',\n",
    "            name='decoder_dense'\n",
    "        )\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        self.training_model = keras.models.Model(\n",
    "            inputs=[encoder_inputs, decoder_inputs],\n",
    "            outputs=decoder_outputs\n",
    "        )\n",
    "    \n",
    "    def build_inference_model(self):\n",
    "        # Encoder\n",
    "        encoder_inputs = keras.layers.Input(shape=(None,), name='encoder_inputs')\n",
    "        encoder_embedding_layer = self.training_model.get_layer('encoder_embedding')\n",
    "        encoder_embedding = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "        encoder_outputs = encoder_embedding\n",
    "        encoder_states = []\n",
    "        for i in range(self.encoder_layers):\n",
    "            encoder_rnn_layer = self.training_model.get_layer(f'encoder_{i}')\n",
    "            encoder_outputs, *state = encoder_rnn_layer(encoder_outputs)\n",
    "            encoder_states.extend(state)\n",
    "\n",
    "        self.encoder_model = keras.models.Model(\n",
    "            inputs=encoder_inputs,\n",
    "            outputs=encoder_states\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        decoder_inputs = keras.layers.Input(shape=(None,), name='decoder_inputs')\n",
    "        decoder_embedding_layer = self.training_model.get_layer('decoder_embedding')\n",
    "        decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "        decoder_states_inputs = []\n",
    "        for idx, state in enumerate(encoder_states):\n",
    "            decoder_states_inputs.append(\n",
    "                keras.layers.Input(shape=(self.hidden_units,), name=f'decoder_state_input_{idx}')\n",
    "            )\n",
    "\n",
    "        decoder_outputs = decoder_embedding\n",
    "        decoder_states = []\n",
    "\n",
    "        state_idx = 0\n",
    "        for i in range(self.decoder_layers):\n",
    "            decoder_rnn_layer = self.training_model.get_layer(f'decoder_{i}')\n",
    "            if self.decoder_type == 'LSTM':\n",
    "                init_h = decoder_states_inputs[state_idx]\n",
    "                init_c = decoder_states_inputs[state_idx + 1]\n",
    "                decoder_outputs, state_h, state_c = decoder_rnn_layer(\n",
    "                    decoder_outputs, initial_state=[init_h, init_c]\n",
    "                )\n",
    "                decoder_states.extend([state_h, state_c])\n",
    "                state_idx += 2\n",
    "            else:\n",
    "                init_h = decoder_states_inputs[state_idx]\n",
    "                decoder_outputs, state_h = decoder_rnn_layer(\n",
    "                    decoder_outputs, initial_state=[init_h]\n",
    "                )\n",
    "                decoder_states.append(state_h)\n",
    "                state_idx += 1\n",
    "\n",
    "        decoder_dense_layer = self.training_model.get_layer('decoder_dense')\n",
    "        decoder_outputs = decoder_dense_layer(decoder_outputs)\n",
    "\n",
    "        self.decoder_model = keras.models.Model(\n",
    "            inputs=[decoder_inputs] + decoder_states_inputs,\n",
    "            outputs=[decoder_outputs] + decoder_states\n",
    "        )\n",
    "    \n",
    "    def compile(self, optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy']):\n",
    "        self.training_model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics\n",
    "        )\n",
    "    \n",
    "    def fit(self, x, y, batch_size=64, epochs=10, validation_split=0):\n",
    "        self.training_model.fit(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=validation_split,\n",
    "        )\n",
    "\n",
    "    def evaluate(\n",
    "        self,\n",
    "        input_seqs,\n",
    "        target_seqs,\n",
    "        start_token,\n",
    "        end_token,\n",
    "        max_dec_len,\n",
    "        batch_size=64):\n",
    "        \"\"\"\n",
    "        Batched beam search decoding + exact‐match accuracy.\n",
    "        Uses one big GPU call per time‐step over all (batch×beam) hypotheses.\n",
    "        \"\"\"\n",
    "        N = input_seqs.shape[0]\n",
    "        n_batches = math.ceil(N / batch_size)\n",
    "        total_correct = 0\n",
    "\n",
    "        for bi in range(n_batches):\n",
    "            \n",
    "            batch_inputs = input_seqs[bi*batch_size : (bi+1)*batch_size]\n",
    "            bsz = batch_inputs.shape[0]\n",
    "\n",
    "            enc_states = self.encoder_model.predict(batch_inputs, verbose=0)\n",
    "\n",
    "            B = self.beam_width\n",
    "            flat_states = []\n",
    "            for state in enc_states:\n",
    "                tiled = np.repeat(state[:, None, :], B, axis=1)\n",
    "                flat_states.append(tiled.reshape(bsz*B, -1))\n",
    "\n",
    "            flat_dec_input = np.full((bsz*B, 1), start_token, dtype='int32')\n",
    "\n",
    "            seqs   = [[[start_token]] * B for _ in range(bsz)]\n",
    "            scores = np.zeros((bsz, B), dtype=np.float32)\n",
    "\n",
    "            for t in range(max_dec_len):\n",
    "                inputs = [flat_dec_input] + flat_states\n",
    "                outs   = self.decoder_model.predict(inputs, verbose=0)\n",
    "                logits = outs[0]                \n",
    "                next_lp = np.log(logits[:,0,:] + 1e-9) \n",
    "\n",
    "                next_lp = next_lp.reshape(bsz, B, -1)\n",
    "\n",
    "                new_seqs  = []\n",
    "                new_scores = []\n",
    "                new_states = [np.zeros_like(s) for s in flat_states]\n",
    "\n",
    "                for i in range(bsz):\n",
    "                    total_lp = scores[i][:, None] + next_lp[i]   \n",
    "                    flat_indices = total_lp.reshape(-1)      \n",
    "\n",
    "                    topk_idx = np.argpartition(-flat_indices, B-1)[:B]\n",
    "                    topk_scores = flat_indices[topk_idx]\n",
    "\n",
    "                    prev_beam = topk_idx // next_lp.shape[2]   \n",
    "                    token_id  = topk_idx %  next_lp.shape[2]      \n",
    "\n",
    "                    bs_seqs = []\n",
    "                    for j, (bprev, tok) in enumerate(zip(prev_beam, token_id)):\n",
    "                        seq = seqs[i][bprev] + [int(tok)]\n",
    "                        bs_seqs.append(seq)\n",
    "\n",
    "                        src_idx = i*B + bprev\n",
    "                        dst_idx = i*B + j\n",
    "                        for k, st in enumerate(outs[1:]):\n",
    "                            new_states[k][dst_idx] = st[src_idx]\n",
    "\n",
    "                    new_seqs.append(bs_seqs)\n",
    "                    new_scores.append(topk_scores)\n",
    "\n",
    "                seqs   = new_seqs\n",
    "                scores = np.stack(new_scores, axis=0)\n",
    "                flat_states = [ns.reshape(bsz*B, -1) for ns in new_states]\n",
    "                last_tokens = [ [s[-1] for s in bs] for bs in seqs ]\n",
    "                flat_dec_input = np.array(last_tokens).reshape(-1,1)\n",
    "\n",
    "                if all(s[-1] == end_token for bs in seqs for s in bs):\n",
    "                    break\n",
    "\n",
    "            batch_preds = []\n",
    "            for bs in seqs:\n",
    "                best_idx = int(np.argmax([scores[i,j] for j in range(B)]))\n",
    "                seq = bs[best_idx]\n",
    "                seq = [tok for tok in seq if tok not in (start_token,)]\n",
    "                if end_token in seq:\n",
    "                    seq = seq[:seq.index(end_token)]\n",
    "                seq += [0] * (max_dec_len - len(seq))\n",
    "                batch_preds.append(seq)\n",
    "\n",
    "            tgt_slice = target_seqs[bi*batch_size : bi*batch_size+bsz]\n",
    "            for p, t in zip(batch_preds, tgt_slice):\n",
    "                if np.array_equal(p, t):\n",
    "                    total_correct += 1\n",
    "\n",
    "        return total_correct / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-05-17T09:59:53.873611Z",
     "iopub.status.busy": "2025-05-17T09:59:53.873323Z",
     "iopub.status.idle": "2025-05-17T09:59:53.896649Z",
     "shell.execute_reply": "2025-05-17T09:59:53.895869Z",
     "shell.execute_reply.started": "2025-05-17T09:59:53.873590Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.W1 = Dense(units)\n",
    "        self.W2 = Dense(units)\n",
    "        self.V  = Dense(1)\n",
    "\n",
    "    def call(self, query, values, mask=None):\n",
    "        q_expanded = tf.expand_dims(query, 2)\n",
    "        v_expanded = tf.expand_dims(values, 1)\n",
    "\n",
    "        score = self.V(tf.nn.tanh(self.W1(q_expanded) + self.W2(v_expanded)))\n",
    "\n",
    "        if mask is not None and mask[1] is not None:\n",
    "            enc_mask = tf.expand_dims(mask[1], 1)\n",
    "            score -= (1.0 - tf.cast(enc_mask, score.dtype)) * 1e9\n",
    "\n",
    "        attn_weights = tf.nn.softmax(score, axis=2)       \n",
    "        attn_weights = tf.squeeze(attn_weights, -1)       \n",
    "        context = tf.matmul(attn_weights, values)     \n",
    "\n",
    "        return context, attn_weights\n",
    "\n",
    "class Seq2SeqAttention:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_vocab_size,\n",
    "        output_vocab_size,\n",
    "        embedding_dim,\n",
    "        hidden_units,\n",
    "        dropout_rate=0.0,\n",
    "        recurrent_dropout_rate=0.0,\n",
    "        encoder_type='LSTM',\n",
    "        decoder_type='LSTM',\n",
    "        beam_width = 1\n",
    "    ):\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_units = hidden_units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.recurrent_dropout_rate = recurrent_dropout_rate\n",
    "        self.encoder_type = encoder_type\n",
    "        self.decoder_type = decoder_type\n",
    "        self.beam_width = beam_width\n",
    "\n",
    "    def build_training_model(self):\n",
    "        enc_inputs = Input(shape=(None,), name='encoder_inputs')\n",
    "        enc_emb = Embedding(\n",
    "            self.input_vocab_size,\n",
    "            self.embedding_dim,\n",
    "            mask_zero=True,\n",
    "            name='encoder_embedding'\n",
    "        )(enc_inputs)\n",
    "\n",
    "        EncoderCell = getattr(tf.keras.layers, self.encoder_type)\n",
    "        self.encoder_rnn = EncoderCell(\n",
    "            self.hidden_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            dropout=self.dropout_rate,\n",
    "            recurrent_dropout=self.recurrent_dropout_rate,\n",
    "            name='encoder_'+self.encoder_type.lower()\n",
    "        )\n",
    "        enc_outputs_and_states = self.encoder_rnn(enc_emb)\n",
    "        enc_outputs, *enc_states = enc_outputs_and_states\n",
    "\n",
    "        dec_inputs = Input(shape=(None,), name='decoder_inputs')\n",
    "        dec_emb = Embedding(\n",
    "            self.output_vocab_size,\n",
    "            self.embedding_dim,\n",
    "            mask_zero=True,\n",
    "            name='decoder_embedding'\n",
    "        )(dec_inputs)\n",
    "\n",
    "        DecoderCell = getattr(tf.keras.layers, self.decoder_type)\n",
    "        self.decoder_rnn = DecoderCell(\n",
    "            self.hidden_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            dropout=self.dropout_rate,\n",
    "            recurrent_dropout=self.recurrent_dropout_rate,\n",
    "            name='decoder_'+self.decoder_type.lower()\n",
    "        )\n",
    "        dec_outputs_and_states = self.decoder_rnn(\n",
    "            dec_emb, initial_state=enc_states\n",
    "        )\n",
    "        dec_outputs, *dec_states = dec_outputs_and_states\n",
    "\n",
    "        self.attention_layer = BahdanauAttention(\n",
    "            self.hidden_units, name='bahdanau_attn'\n",
    "        )\n",
    "        context, _ = self.attention_layer(\n",
    "            dec_outputs, enc_outputs\n",
    "        )\n",
    "\n",
    "        concat = Concatenate(axis=-1, name='concat_layer')([dec_outputs, context])\n",
    "        dec_logits = Dense(\n",
    "            self.output_vocab_size,\n",
    "            activation='softmax',\n",
    "            name='output_dense'\n",
    "        )(concat)\n",
    "\n",
    "        self.training_model = Model(\n",
    "            inputs=[enc_inputs, dec_inputs],\n",
    "            outputs=dec_logits,\n",
    "            name='seq2seq_training'\n",
    "        )\n",
    "        \n",
    "    def build_inference_model(self):\n",
    "        enc_inputs_inf = Input(\n",
    "            shape=(None,), name='encoder_inputs_inf'\n",
    "        )\n",
    "        enc_emb_inf = self._training_model.get_layer('encoder_embedding')(\n",
    "            enc_inputs_inf\n",
    "        )\n",
    "        enc_rnn = self._training_model.get_layer(\n",
    "            'encoder_'+self.encoder_type.lower()\n",
    "        )\n",
    "        enc_outputs_and_states = enc_rnn(enc_emb_inf)\n",
    "        enc_outputs_inf, *enc_states_inf = enc_outputs_and_states\n",
    "\n",
    "        self.encoder_model = Model(\n",
    "            inputs=enc_inputs_inf,\n",
    "            outputs=[enc_outputs_inf] + enc_states_inf,\n",
    "            name='encoder_inference'\n",
    "        )\n",
    "\n",
    "        dec_token_inf   = Input(shape=(1,), name='decoder_token_inf')\n",
    "        enc_outputs_inp = Input(\n",
    "            shape=(None, self.hidden_units),\n",
    "            name='encoder_outputs_inf'\n",
    "        )\n",
    "\n",
    "        dec_state_inputs = [\n",
    "            Input(shape=(self.hidden_units,), name=f'decoder_state_inf_{i}')\n",
    "            for i in range(len(enc_states_inf))\n",
    "        ]\n",
    "\n",
    "        dec_emb_inf = self._training_model.get_layer('decoder_embedding')(\n",
    "            dec_token_inf\n",
    "        )\n",
    "        dec_rnn = self._training_model.get_layer(\n",
    "            'decoder_'+self.decoder_type.lower()\n",
    "        )\n",
    "        dec_outputs_and_states_inf = dec_rnn(\n",
    "            dec_emb_inf, initial_state=dec_state_inputs\n",
    "        )\n",
    "        dec_out_step, *dec_states_out = dec_outputs_and_states_inf\n",
    "\n",
    "        context_inf, _ = self.attention_layer(\n",
    "            dec_out_step, enc_outputs_inp\n",
    "        )\n",
    "        concat_inf = Concatenate(axis=-1)([dec_out_step, context_inf])\n",
    "        dec_logits_inf = self._training_model.get_layer('output_dense')(\n",
    "            concat_inf\n",
    "        )\n",
    "\n",
    "        self.decoder_model = Model(\n",
    "            inputs=[dec_token_inf, enc_outputs_inp] + dec_state_inputs,\n",
    "            outputs=[dec_logits_inf] + dec_states_out,\n",
    "            name='decoder_inference'\n",
    "        )\n",
    "\n",
    "    def compile(self, optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy']):\n",
    "        self.training_model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics\n",
    "        )\n",
    "    \n",
    "    def fit(self, x, y, batch_size=64, epochs=10, validation_split=0):\n",
    "        self.training_model.fit(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=validation_split,\n",
    "        )\n",
    "    \n",
    "    def evaluate(\n",
    "        self,\n",
    "        input_seqs,\n",
    "        target_seqs,\n",
    "        start_token,\n",
    "        end_token,\n",
    "        max_dec_len,\n",
    "        batch_size=64):\n",
    "        \"\"\"\n",
    "        Batched beam search decoding + exact‐match accuracy.\n",
    "        Uses one big GPU call per time‐step over all (batch×beam) hypotheses.\n",
    "        \"\"\"\n",
    "        N = input_seqs.shape[0]\n",
    "        n_batches = math.ceil(N / batch_size)\n",
    "        total_correct = 0\n",
    "        predictions = []\n",
    "\n",
    "        for bi in range(n_batches):\n",
    "            \n",
    "            batch_inputs = input_seqs[bi*batch_size : (bi+1)*batch_size]\n",
    "            bsz = batch_inputs.shape[0]\n",
    "\n",
    "            enc_states = self.encoder_model.predict(batch_inputs, verbose=0)\n",
    "\n",
    "            B = self.beam_width\n",
    "            flat_states = []\n",
    "            for state in enc_states:\n",
    "                tiled = np.repeat(state[:, None, :], B, axis=1)\n",
    "                flat_states.append(tiled.reshape(bsz*B, -1))\n",
    "\n",
    "            flat_dec_input = np.full((bsz*B, 1), start_token, dtype='int32')\n",
    "\n",
    "            seqs   = [[[start_token]] * B for _ in range(bsz)]\n",
    "            scores = np.zeros((bsz, B), dtype=np.float32)\n",
    "\n",
    "            for t in range(max_dec_len):\n",
    "                inputs = [flat_dec_input] + flat_states\n",
    "                outs   = self.decoder_model.predict(inputs, verbose=0)\n",
    "                logits = outs[0]                \n",
    "                next_lp = np.log(logits[:,0,:] + 1e-9) \n",
    "\n",
    "                next_lp = next_lp.reshape(bsz, B, -1)\n",
    "\n",
    "                new_seqs  = []\n",
    "                new_scores = []\n",
    "                new_states = [np.zeros_like(s) for s in flat_states]\n",
    "\n",
    "                for i in range(bsz):\n",
    "                    total_lp = scores[i][:, None] + next_lp[i]   \n",
    "                    flat_indices = total_lp.reshape(-1)      \n",
    "\n",
    "                    topk_idx = np.argpartition(-flat_indices, B-1)[:B]\n",
    "                    topk_scores = flat_indices[topk_idx]\n",
    "\n",
    "                    prev_beam = topk_idx // next_lp.shape[2]   \n",
    "                    token_id  = topk_idx %  next_lp.shape[2]      \n",
    "\n",
    "                    bs_seqs = []\n",
    "                    for j, (bprev, tok) in enumerate(zip(prev_beam, token_id)):\n",
    "                        seq = seqs[i][bprev] + [int(tok)]\n",
    "                        bs_seqs.append(seq)\n",
    "\n",
    "                        src_idx = i*B + bprev\n",
    "                        dst_idx = i*B + j\n",
    "                        for k, st in enumerate(outs[1:]):\n",
    "                            new_states[k][dst_idx] = st[src_idx]\n",
    "\n",
    "                    new_seqs.append(bs_seqs)\n",
    "                    new_scores.append(topk_scores)\n",
    "\n",
    "                seqs   = new_seqs\n",
    "                scores = np.stack(new_scores, axis=0)\n",
    "                flat_states = [ns.reshape(bsz*B, -1) for ns in new_states]\n",
    "                last_tokens = [ [s[-1] for s in bs] for bs in seqs ]\n",
    "                flat_dec_input = np.array(last_tokens).reshape(-1,1)\n",
    "\n",
    "                if all(s[-1] == end_token for bs in seqs for s in bs):\n",
    "                    break\n",
    "\n",
    "            batch_preds = []\n",
    "            for bs in seqs:\n",
    "                best_idx = int(np.argmax([scores[i,j] for j in range(B)]))\n",
    "                seq = bs[best_idx]\n",
    "                seq = [tok for tok in seq if tok not in (start_token,)]\n",
    "                if end_token in seq:\n",
    "                    seq = seq[:seq.index(end_token)]\n",
    "                seq += [0] * (max_dec_len - len(seq))\n",
    "                batch_preds.append(seq)\n",
    "\n",
    "            tgt_slice = target_seqs[bi*batch_size : bi*batch_size+bsz]\n",
    "            for p, t in zip(batch_preds, tgt_slice):\n",
    "                if np.array_equal(p, t):\n",
    "                    total_correct += 1\n",
    "            \n",
    "            predictions.extend(batch_preds)\n",
    "\n",
    "        return total_correct / N, predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use GPU 0; change if needed\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPUs found: {[gpu.name for gpu in gpus]}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found, running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "!wandb login "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to get the config value from wandb or command line arguments\n",
    "def get_config_value(config, args, key, default=None):\n",
    "    return getattr(config, key, getattr(args, key, default))\n",
    "\n",
    "def train_model(config=None):\n",
    "    # set default hyperparameters\n",
    "    defaults = {\n",
    "        'embedding_dim': 256,\n",
    "        'hidden_units': 512,\n",
    "        'dropout_rate': 0.2,\n",
    "        'recurrent_dropout_rate': 0.2,\n",
    "        'encoder_layers': 1,\n",
    "        'decoder_layers': 1,\n",
    "        'cell_type': 'LSTM',\n",
    "        'beam_width': 1,\n",
    "        'dataset': '/kaggle/input/as3-dataset/lexicons',\n",
    "        'attention': False,\n",
    "        'do_val':True,\n",
    "        'do_test': False,\n",
    "    }\n",
    "\n",
    "    # Initialize wandb with the provided entity and project\n",
    "    with wandb.init(entity='me21b138-indian-institute-of-technology-madras', project='AS3', config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        # Create a class to mimic argparse for the helper functions\n",
    "        class Args:\n",
    "            def __init__(self, **kwargs):\n",
    "                for key, value in kwargs.items():\n",
    "                    setattr(self, key, value)\n",
    "\n",
    "        # Set up args with defaults\n",
    "        args = Args(**defaults)\n",
    "\n",
    "        data = extract_data()\n",
    "        train_data = data['train']\n",
    "        dev_data = data['dev']\n",
    "        test_data = data['test']\n",
    "\n",
    "        encoder_tokenizer = tokanize_texts(np.concatenate((dev_data[:,1], train_data[:,1]), axis=0))\n",
    "        decoder_tokenizer = tokanize_texts(np.concatenate((dev_data[:,0], train_data[:,0]), axis=0), start_end_tokens=True)\n",
    "\n",
    "        train_x = encoder_tokenizer.texts_to_sequences(train_data[:,1])\n",
    "        train_y = decoder_tokenizer.texts_to_sequences(train_data[:,0])\n",
    "        dev_x = encoder_tokenizer.texts_to_sequences(dev_data[:,1])\n",
    "        dev_y = decoder_tokenizer.texts_to_sequences(dev_data[:,0])\n",
    "        test_x = encoder_tokenizer.texts_to_sequences(test_data[:,1])\n",
    "        test_y = decoder_tokenizer.texts_to_sequences(test_data[:,0])\n",
    "\n",
    "        max_encoder_seq_length = max([len(seq) for seq in train_x + dev_x + test_x])\n",
    "        max_decoder_seq_length = max([len(seq) for seq in train_y + dev_y + test_y])\n",
    "\n",
    "        train_x = pad_sequences(train_x, maxlen=max_encoder_seq_length, padding='post')\n",
    "        dev_x = pad_sequences(dev_x, maxlen=max_encoder_seq_length, padding='post')\n",
    "        test_x = pad_sequences(test_x, maxlen=max_encoder_seq_length, padding='post')\n",
    "\n",
    "        train_y = pad_sequences(train_y, maxlen=max_decoder_seq_length, padding='post')\n",
    "        dev_y = pad_sequences(dev_y, maxlen=max_decoder_seq_length, padding='post')\n",
    "        test_y = pad_sequences(test_y, maxlen=max_decoder_seq_length, padding='post')\n",
    "        train_x = train_x\n",
    "        train_y = train_y\n",
    "        dev_x = dev_x\n",
    "        dev_y = dev_y\n",
    "\n",
    "        input_vocab_size = len(encoder_tokenizer.word_index) + 1\n",
    "        output_vocab_size = len(decoder_tokenizer.word_index) + 1\n",
    "        train_y_cat = np.eye(output_vocab_size)[train_y]\n",
    "\n",
    "        model = None\n",
    "        \n",
    "        if get_config_value(config, args, 'attention'):\n",
    "            model = Seq2SeqAttention(\n",
    "                input_vocab_size=input_vocab_size,\n",
    "                output_vocab_size=output_vocab_size,\n",
    "                embedding_dim=get_config_value(config, args, 'embedding_dim'),\n",
    "                hidden_units=get_config_value(config, args, 'hidden_units'),\n",
    "                dropout_rate=get_config_value(config, args, 'dropout_rate'),\n",
    "                recurrent_dropout_rate=get_config_value(config, args, 'recurrent_dropout_rate'),\n",
    "                encoder_type=get_config_value(config, args, 'cell_type'),\n",
    "                decoder_type=get_config_value(config, args, 'cell_type'),\n",
    "                beam_width=get_config_value(config, args, 'beam_width')\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            model = seq2seq(\n",
    "                input_vocab_size=input_vocab_size,\n",
    "                output_vocab_size=output_vocab_size,\n",
    "                embedding_dim=get_config_value(config, args, 'embedding_dim'),\n",
    "                hidden_units=get_config_value(config, args, 'hidden_units'),\n",
    "                encoder_layers=get_config_value(config, args, 'encoder_layers'),\n",
    "                decoder_layers=get_config_value(config, args, 'decoder_layers'),\n",
    "                dropout_rate=get_config_value(config, args, 'dropout_rate'),\n",
    "                recurrent_dropout_rate=get_config_value(config, args, 'recurrent_dropout_rate'),\n",
    "                encoder_type=get_config_value(config, args, 'cell_type'),\n",
    "                decoder_type=get_config_value(config, args, 'cell_type'),\n",
    "                beam_width=get_config_value(config, args, 'beam_width')\n",
    "            )\n",
    "        \n",
    "        model.build_training_model()\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        model.fit(\n",
    "            x=[train_x, train_y],\n",
    "            y=train_y_cat,\n",
    "            batch_size=400,\n",
    "            epochs=10,\n",
    "            validation_split=0.2\n",
    "        )\n",
    "        model.build_inference_model()\n",
    "\n",
    "\n",
    "        dev_y_eval = dev_y[:, 1:]\n",
    "        test_y_eval = test_y[:, 1:]\n",
    "\n",
    "        if get_config_value(config, args, 'do_val'):  \n",
    "            dev_acc, dev_prediction = model.evaluate(\n",
    "                input_seqs=dev_x,\n",
    "                target_seqs=dev_y_eval,\n",
    "                start_token=decoder_tokenizer.word_index['<start>'],\n",
    "                end_token=decoder_tokenizer.word_index['<end>'],\n",
    "                max_dec_len=dev_y_eval.shape[1],\n",
    "                batch_size=1000\n",
    "            )\n",
    "            wandb.log({\"validation_accuracy\": dev_acc})\n",
    "\n",
    "        if get_config_value(config, args, 'do_test'):\n",
    "            test_acc, test_prediction = model.evaluate(\n",
    "                input_seqs=test_x,\n",
    "                target_seqs=test_y_eval,\n",
    "                start_token=decoder_tokenizer.word_index['<start>'],\n",
    "                end_token=decoder_tokenizer.word_index['<end>'],\n",
    "                max_dec_len=dev_y_eval.shape[1],\n",
    "                batch_size=1000\n",
    "            )\n",
    "            wandb.log({\"test_accuracy\": test_acc})\n",
    "\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "        'name': 'validation_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'embedding_dim': {\n",
    "            'values': [16, 32, 64, 128, 256, 512]\n",
    "        },\n",
    "        'hidden_units': {\n",
    "            'values': [16, 32, 64, 128, 256, 512]\n",
    "        },\n",
    "        'dropout_rate': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.0,\n",
    "            'max': 0.5\n",
    "        },\n",
    "        'recurrent_dropout_rate': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.0,\n",
    "            'max': 0.5\n",
    "        },\n",
    "        'encoder_layers': {\n",
    "            'values': [1, 2, 3]\n",
    "        },\n",
    "        'decoder_layers': {\n",
    "            'values': [1, 2, 3]\n",
    "        },\n",
    "        'cell_type': {\n",
    "            'values': ['RNN', 'LSTM', 'GRU']\n",
    "        },\n",
    "        'beam_width': {\n",
    "            'values': [1, 2, 3]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for the sweep\n",
    "entity = 'me21b138-indian-institute-of-technology-madras'  # Your wandb entity\n",
    "project = 'AS3'  # Your wandb project\n",
    "count = 100  # Number of runs to execute\n",
    "\n",
    "# Initialize the sweep\n",
    "wandb.require(\"core\")\n",
    "sweep_id = wandb.sweep(sweep_config, entity=entity, project=project)\n",
    "\n",
    "# Start the sweep agent\n",
    "wandb.agent(sweep_id, function=train_model, count=count)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7429446,
     "sourceId": 11826686,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
